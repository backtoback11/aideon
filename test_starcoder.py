import sys
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

def test_starcoder_local(local_path, device_map="mps"):
    print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å StarCoder –∏–∑: {local_path}")
    model = None
    tokenizer = None
    try:
        # 1) –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        tokenizer = AutoTokenizer.from_pretrained(
            local_path,
            local_files_only=True,
            trust_remote_code=True
        )

        # 2) –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = AutoModelForCausalLM.from_pretrained(
            local_path,
            local_files_only=True,
            trust_remote_code=True,
            torch_dtype=torch.float32,  # –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ float16, –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ torch.float16
            device_map=device_map       # "mps" –∏–ª–∏ "cpu"
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

        # 3) –ú–∏–Ω–∏-—Ç–µ—Å—Ç –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        prompt = "def greet(name):\n    return f'Hello, {name}'"
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        print("–í—ã–ø–æ–ª–Ω—è–µ–º generate()...")

        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        out_tokens = model.generate(
            **inputs,
            max_new_tokens=8,
            do_sample=True,   # –æ—Ç–∫–ª—é—á–∞–µ–º —Å—ç–º–ø–ª–∏–Ω–≥, —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–µ–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å
            temperature=0.1
        )

        result = tokenizer.decode(out_tokens[0], skip_special_tokens=True)
        print("\n===== –†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ =====\n")
        print(result)
        print("\n===== –£—Å–ø–µ—Ö! =====")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å–æ StarCoder: {e}")

    finally:
        # –ü–æ–ø—ã—Ç–∫–∞ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –ø–∞–º—è—Ç—å –∏ –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
        if model is not None:
            print("üóë –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É: –ø–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ CPU –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Å—Å—ã–ª–∫–∏.")
            try:
                model.to("cpu")
            except:
                pass
        del model
        del tokenizer

        # –î–ª—è CUDA –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å:
        # torch.cuda.empty_cache()

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞
        sys.exit(0)

if __name__ == "__main__":
    # –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—å—é StarCoder
    local_path = "/Users/backtoback/models/starcoder/starcoder-7B"

    # –ú–æ–∂–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å device_map="cpu", –µ—Å–ª–∏ MPS –≤—ã–∑—ã–≤–∞–µ—Ç OOM
    test_starcoder_local(local_path, device_map="mps")